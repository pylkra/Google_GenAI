{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🧠 Gemini-powered Mental Health Assistant\nA warm, supportive mental health chatbot using **Google's Gemini** model and CBT techniques.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Remove conflicting packages from the Kaggle base environment.\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n# Install langgraph and the packages used in this lab.\n!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔧 Installing Required Packages for RAG\n\nWe need to install a few additional packages for setting up Retrieval-Augmented Generation (RAG):\n\n- `faiss-cpu`: Vector database for efficient similarity search\n- `langchain-community`: Extra loaders and retrievers\n- `tiktoken`: For token counting used by language models\n\nThese help us build a vector store for mental health documents.\n","metadata":{}},{"cell_type":"code","source":"# Install additional dependencies for RAG\n!pip install -qU faiss-cpu tiktoken langchain-community\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"from langchain_google_genai import GoogleGenerativeAIEmbeddings\n!pip install langchain-google-genai","metadata":{"execution":{"iopub.status.busy":"2025-04-19T17:01:45.081548Z","iopub.execute_input":"2025-04-19T17:01:45.081911Z","iopub.status.idle":"2025-04-19T17:01:51.264117Z","shell.execute_reply.started":"2025-04-19T17:01:45.081881Z","shell.execute_reply":"2025-04-19T17:01:51.263136Z"}}},{"cell_type":"markdown","source":"## 📚 Setting Up the Vector Store with Embeddings\n\nWe’ll now:\n\n- Load a publicly available [Mental Health Guide PDF](https://f.hubspotusercontent00.net/hubfs/190206/Mental%20Health%20Guide.pdf)\n- Convert it into text chunks\n- Embed those chunks using Google Generative AI embeddings\n- Store them in a FAISS vector index for fast retrieval\n\nThis allows our assistant to pull in helpful and informed context!\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries for RAG\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.schema.runnable import RunnableMap\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import RetrievalQA\n\nimport os\n\n# Set up the embedding model\nembedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n\n# Load and split sample knowledge base documents (replace with your own if needed)\ndocs = [\n    \"Mindfulness involves being present in the moment without judgment.\",\n    \"Cognitive Behavioral Therapy helps identify and reframe negative thinking patterns.\",\n    \"Daily journaling can promote emotional awareness and reduce stress.\",\n    \"Deep breathing exercises are effective for managing anxiety in the moment.\",\n]\ndocuments = [{\"page_content\": doc} for doc in docs]\n\n# Split and embed documents\ntext_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10)\nsplit_docs = text_splitter.create_documents([d[\"page_content\"] for d in documents])\n\n# Create a FAISS vector store\nvectorstore = FAISS.from_documents(split_docs, embedding_model)\n\n# Set up retriever\nretriever = vectorstore.as_retriever()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔍 Retriever Node\n\nThis LangGraph node retrieves relevant text chunks from the vector store using user queries. The retrieved text will be passed to the response generation step.\n","metadata":{}},{"cell_type":"code","source":"# RAG node function for LangGraph\ndef retrieve_context(state):\n    \"\"\"Retrieve relevant documents from vectorstore given the user input.\"\"\"\n    query = state[\"messages\"][-1][\"content\"]\n    docs = retriever.get_relevant_documents(query)\n    retrieved_text = \"\\n\".join([doc.page_content for doc in docs])\n    state[\"retrieved_docs\"] = retrieved_text\n    return state\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🧠 Response Generator Node with RAG\n\nWe use a Gemini model to generate responses **informed by the retrieved documents**. The prompt includes both the user’s message and the retrieved mental health context.\n\nThis makes the assistant more helpful and grounded.\n","metadata":{}},{"cell_type":"code","source":"# Example LangGraph integration (assuming `workflow` is your graph)\nfrom typing import TypedDict\nfrom langgraph.graph import StateGraph\n\n# Step 1: Define the state schema\nclass MentalHealthState(TypedDict):\n    user_input: str\n    retrieved_context: str\n    generate_response: str\n\n# Step 2: Define your node functions\ndef retrieve_context(state: MentalHealthState) -> dict:\n    user_input = state[\"user_input\"]\n    # Pretend this is a RAG retrieval or similar\n    return {\"retrieved_context\": f\"Context for: {user_input}\"}\n\ndef generate_response(state: MentalHealthState) -> dict:\n    context = state[\"retrieved_context\"]\n    # Pretend this is calling a language model\n    return {\"generate_response\": f\"Response based on: {context}\"}\n\n# Step 3: Build the LangGraph\nbuilder = StateGraph(state_schema=MentalHealthState)\n\nbuilder.add_node(\"retrieve_context\", retrieve_context)\nbuilder.add_node(\"generate_response_node\", generate_response)\n\nbuilder.add_edge(\"retrieve_context\", \"generate_response_node\")\nbuilder.set_entry_point(\"retrieve_context\")\n\nworkflow = builder.compile()\n\n# Step 4: Run it!\nfinal_output = workflow.invoke({\"user_input\": \"I feel anxious about work.\"})\nprint(final_output)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔗 Integrating the Retriever into the Graph\n\nWe now wire the `retrieve_context` node into the LangGraph flow. The graph sequence becomes:\n\n`user_input → retrieve_context → generate_response`\n","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom google.api_core import retry\n\nfrom IPython.display import HTML, Markdown, display\n\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install langgraph","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from typing import Annotated\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph.message import add_messages","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class InnerTrans(TypedDict):\n    \"\"\"State representing the client's mental state conversation.\"\"\"\n\n    # The chat conversation. This preserves the conversation history\n    # between nodes. The `add_messages` annotation indicates to LangGraph\n    # that state is updated by appending returned messages, not replacing\n    # them.\n    messages: Annotated[list, add_messages]\n\n    # The customer's in-progress order.\n    #order: list[str]\n\n    # Flag indicating that the order is placed and completed.\n    finished: bool\n\n\n# The system instruction defines how the chatbot is expected to behave and includes\n# rules for when to call different functions, as well as rules for the conversation, such\n# as tone and what is permitted for discussion.\nTRANSFORMBOT_SYSINT = (\n    \"system\",\n    \"You are Inner Transformation Bot, an interactive mental wellness guide designed to support users on their journey of self-awareness, emotional balance, and inner growth. A human will speak with you about their feelings, thoughts, and experiences, and you will guide them through a series of supportive reflections, self-assessment tools, and healing prompts.\"\n    \"\\n\\n\"\n    \"Always be prepared to offer a grounding prompt or breath-based exercise if the user seems overwhelmed or anxious. A grounding prompt might include a gentle breath cue, sensory check-in, or body awareness exercise.\"\n    \"\\n\\n\"\n    \"You are equipped with tools to help the user explore their current emotional state (`check_mood`), suggest personalized activities (`suggest_practice`), help reframe negative thoughts (`reframe_thought`), retrieve relevant insights from a healing wisdom library (`retrieve_wisdom`), and facilitate a closing reflection (`close_session`).\"\n    \"\\n\\n\"\n    \"Always begin with a gentle greeting and an invitation to check in emotionally. From there, dynamically assess their needs and route them through the most helpful support path. \"\n    \"Use empathetic language and avoid clinical terminology unless asked. Your tone should be grounding, compassionate, and curious.\"\n    \"\\n\\n\"\n    \"If the user shares a negative or heavy thought, reflect it back gently and offer a positive reframe. If the user is uncertain or vague, ask clarifying questions to help them explore further. \"\n    \"\\n\\n\"\n    \"Each response should feel like a mindful conversation — no rapid-fire questioning, no judgments. Always prioritize the user's emotional safety and autonomy.\"\n    \"\\n\\n\"\n    \"If the user says something playful, off-topic, or humorous (like asking for a latte or making a joke), respond with lightness and warmth, but gently guide the conversation back to emotional well-being. Do not take metaphors too literally or go off-track from your mental wellness role.\"\n)\n# This is the message with which the system opens the conversation.\nWELCOME_MSG = \"Namaste! I'm your Inner Transformation Guide. Let's take a gentle step inward. How are you feeling in this moment?😊\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define a single turn chatbot","metadata":{}},{"cell_type":"code","source":"from langgraph.graph import StateGraph, START, END\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# Try using different models. The Gemini 2.0 flash model is highly\n# capable, great with tools, and has a generous free tier. If you\n# try the older 1.5 models, note that the `pro` models are better at\n# complex multi-tool cases like this, but the `flash` models are\n# faster and have more free quota.\n# Check out the features and quota differences here:\n#  - https://ai.google.dev/gemini-api/docs/models/gemini\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n\n\ndef chatbot(state: InnerTrans) -> InnerTrans:\n    \"\"\"The chatbot itself. A simple wrapper around the model's own chat interface.\"\"\"\n    message_history = [TRANSFORMBOT_SYSINT] + state[\"messages\"]\n    return {\"messages\": [llm.invoke(message_history)]}\n\n\n# Set up the initial graph based on our state definition.\ngraph_builder = StateGraph(InnerTrans)\n\n# Add the chatbot function to the app graph as a node called \"chatbot\".\ngraph_builder.add_node(\"chatbot\", chatbot)\n\n# Define the chatbot node as the app entrypoint.\ngraph_builder.add_edge(START, \"chatbot\")\n\nchat_graph = graph_builder.compile()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\n\nImage(chat_graph.get_graph().draw_mermaid_png())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pprint import pprint\n\nuser_msg = \"Hello, what can you do?\"\nstate = chat_graph.invoke({\"messages\": [user_msg]})\n\n# The state object contains lots of information. Uncomment the pprint lines to see it all.\npprint(state)\n\n# Note that the final state now has 2 messages. Our HumanMessage, and an additional AIMessage.\nfor msg in state[\"messages\"]:\n    print(f\"{type(msg).__name__}: {msg.content}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_msg = \"Oh great, how can you help me?\"\n\nstate[\"messages\"].append(user_msg)\nstate = chat_graph.invoke(state)\n\n# pprint(state)\nfor msg in state[\"messages\"]:\n    print(f\"{type(msg).__name__}: {msg.content}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_core.messages.ai import AIMessage\n\ndef human_node(state: InnerTrans) -> InnerTrans:\n    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n    last_msg = state[\"messages\"][-1]\n    print(\"Model:\", last_msg.content)\n\n    user_input = input(\"User: \")\n\n    # If it looks like the user is trying to quit, flag the conversation\n    # as over.\n    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n        state[\"finished\"] = True\n\n    return state | {\"messages\": [(\"user\", user_input)]} \n\n\n\n\ndef chatbot_with_welcome_msg(state: InnerTrans) -> InnerTrans:\n    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n\n    if state[\"messages\"]:\n        # If there are messages, continue the conversation with the Gemini model.\n        new_output = llm.invoke([TRANSFORMBOT_SYSINT] + state[\"messages\"])\n    else:\n        # If there are no messages, start with the welcome message.\n        new_output = AIMessage(content=WELCOME_MSG)\n\n    return state | {\"messages\": [new_output]}\n\n\n# Start building a new graph.\ngraph_builder = StateGraph(InnerTrans)\n\n# Add the chatbot and human nodes to the app graph.\ngraph_builder.add_node(\"chatbot\", chatbot_with_welcome_msg)\ngraph_builder.add_node(\"human\", human_node)\n\n# Start with the chatbot again.\ngraph_builder.add_edge(START, \"chatbot\")\n\n# The chatbot will always go to the human next.\ngraph_builder.add_edge(\"chatbot\", \"human\");","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from typing import Literal\n\n\ndef maybe_exit_human_node(state: InnerTrans) -> Literal[\"chatbot\", \"__end__\"]:\n    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n    if state.get(\"finished\", False):\n        return END\n    else:\n        return \"chatbot\"\n\n\ngraph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n\nchat_with_human_graph = graph_builder.compile()\n\nImage(chat_with_human_graph.get_graph().draw_mermaid_png())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The default recursion limit for traversing nodes is 25 - setting it higher means\n# you can try a more complex order with multiple steps and round-trips (and you\n# can chat for longer!)\nconfig = {\"recursion_limit\": 100}\n\n# Remember that this will loop forever, unless you input `q`, `quit` or one of the\n# other exit terms defined in `human_node`.\n# Uncomment this line to execute the graph:\nstate = chat_with_human_graph.invoke({\"messages\": []}, config)\n\n# Things to try:\n#  - Just chat! There's no ordering or menu yet.\n#  - 'q' to exit.\n\n# pprint(state)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_core.tools import tool\n@tool\ndef check_mood() -> str:\n    \"\"\"Helps the user reflect on and identify their current mood or emotional state.\"\"\"\n    return (\n        \"Let's take a moment to check in. What emotions are most present for you right now? \"\n        \"You can name one or more feelings, or describe what’s going on internally.\"\n    )\n    \n@tool\ndef get_practices() -> str:\n    \"\"\"Provide a list of supportive mental wellness practices the assistant can recommend.\"\"\"\n\n    return \"\"\"\n    AVAILABLE MENTAL WELLNESS PRACTICES:\n\n    Grounding Techniques:\n    - 5-4-3-2-1 Senses Exercise\n    - Deep Belly Breathing\n    - Body Scan Meditation\n\n    Emotional Check-Ins:\n    - Mood Labeling\n    - Energy Level Assessment\n    - Journaling Prompt\n\n    Cognitive Tools:\n    - Reframing Negative Thoughts\n    - Noticing Thought Patterns\n    - Affirmation Practice\n\n    Self-Soothing Practices:\n    - Guided Visualization\n    - Gentle Movement or Stretching\n    - Self-Compassion Break\n\n    Connection Practices:\n    - Gratitude Reflection\n    - Reach Out to a Friend\n    - Reflect on a Kind Memory\n\n    You can ask for help with any of these, or let me know what you're feeling and I can suggest something that fits your current state.\n    \"\"\"\n@tool\ndef reframe_thought() -> str:\n    \"\"\"Helps the user reframe a negative or limiting belief into a more balanced perspective.\"\"\"\n    return (\n        \"Let’s try to reframe that thought. What’s a belief that’s been weighing on you? \"\n        \"We can look at it together and see if there's a gentler or more empowering way to see it.\"\n    )\n\n@tool\ndef retrieve_wisdom() -> str:\n    \"\"\"Retrieves an insight, quote, or teaching from a mental wellness or healing tradition.\"\"\"\n    return (\n        \"Here's something to reflect on: “You don’t have to control your thoughts. \"\n        \"You just have to stop letting them control you.” – Dan Millman\\n\\n\"\n        \"Would you like another quote or insight?\"\n    )\n@tool\ndef close_session() -> str:\n    \"\"\"Ends the session with a calming reflection and supportive closing message.\"\"\"\n    return (\n        \"As we wrap up, take a deep breath and thank yourself for showing up today. \"\n        \"You're growing in ways you may not even see yet. Be gentle with yourself as you go forward.\"\n    )\n\n\n@tool\ndef suggest_grounding() -> str:\n    \"\"\"Suggests a simple grounding practice to help the user return to the present moment.\"\"\"\n    return (\n        \"Let's try a quick grounding practice. Take a deep breath in... and out. \"\n        \"Now, notice 5 things you can see, 4 things you can touch, 3 things you can hear, \"\n        \"2 things you can smell, and 1 thing you can taste. How do you feel now?\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections.abc import Iterable\nfrom langchain_core.tools import tool\n\n@tool\ndef add_reflection(topic: str, tags: Iterable[str]) -> str:\n    \"\"\"Adds a personal reflection on a topic, optionally labeled with emotional tags.\"\"\"\n    pass\n\n@tool\ndef get_reflections() -> str:\n    \"\"\"Returns the reflections logged in this session.\"\"\"\n    pass\n\n@tool\ndef clear_reflections():\n    \"\"\"Clears the user's reflection log.\"\"\"\n    pass\n\n@tool\ndef complete_session() -> str:\n    \"\"\"Marks the session as complete and offers a closing message.\"\"\"\n    pass\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END\nfrom langchain_core.messages.tool import ToolMessage\nfrom langchain_core.messages import HumanMessage, AIMessage\n# -----------------------------\n# Tool Registration\n# -----------------------------\n\n# === 1. Define tool categories ===\ninner_tools = [check_mood, get_practices, reframe_thought, retrieve_wisdom, close_session, suggest_grounding]\n\nreflection_tools = [add_reflection, get_reflections, clear_reflections, complete_session]\n\n# ToolNode for practice tools (auto-invoked by LangGraph)\npractice_tool_node = ToolNode(inner_tools)\nreflection_node = ToolNode(reflection_tools)\n\n# Bind tools to the LLM\nllm_with_tools = llm.bind_tools(inner_tools + reflection_tools)\n\n\n\n# -----------------------------\n# Message Routing\n# -----------------------------\ndef maybe_route_to_tools(state: InnerTrans) -> str:\n    \"\"\"Route based on which tool was called.\"\"\"\n    if not (msgs := state.get(\"messages\", [])):\n        raise ValueError(f\"No messages found in state: {state}\")\n\n    msg = msgs[-1]\n\n    if state.get(\"finished\", False):\n        return END\n\n    if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n        tool_names = [tool[\"name\"] for tool in msg.tool_calls]\n        if any(name in [\"add_reflection\", \"get_reflections\", \"clear_reflections\", \"complete_session\"] for name in tool_names):\n            return \"reflection\"\n        else:\n            return \"tools\"\n\n    return \"human\"\n\n\nFEW_SHOTS = [\n    HumanMessage(content=\"I feel stuck and unmotivated lately.\"),\n    AIMessage(content=\"That sounds really tough. Can we explore what might be behind those feelings?\"),\n\n    HumanMessage(content=\"I'm not sure. I just don’t feel like myself.\"),\n    AIMessage(content=\"That’s totally okay. Sometimes it helps to name what’s going on—would you like to try a mood check-in?\")\n]\n\ndef chatbot_with_tools(state: InnerTrans) -> InnerTrans:\n    \"\"\"Wrapper around the model's chat interface with tools and few-shot priming.\"\"\"\n    defaults = {\"reflections\": [], \"finished\": False}\n\n    if state.get(\"messages\"):\n        new_output = llm_with_tools.invoke([TRANSFORMBOT_SYSINT] + FEW_SHOTS + state[\"messages\"])\n    else:\n        # If there are no messages, start with the welcome message.\n        new_output = AIMessage(content=WELCOME_MSG)\n\n    return defaults | state | {\"messages\": [new_output]}\n\n\n# -----------------------------\n# Graph Construction\n# -----------------------------\n\ngraph_builder = StateGraph(InnerTrans)\n\n# Add all nodes\ngraph_builder.add_node(\"chatbot\", chatbot_with_tools)\ngraph_builder.add_node(\"human\", human_node)\ngraph_builder.add_node(\"tools\", practice_tool_node)\ngraph_builder.add_node(\"reflection\", reflection_node)\n\n# Routing logic\ngraph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\ngraph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n\n# After tools, return to chatbot\ngraph_builder.add_edge(\"tools\", \"chatbot\")\ngraph_builder.add_edge(\"reflection\", \"chatbot\")\n\n# Start at chatbot\ngraph_builder.add_edge(START, \"chatbot\")\n\n# Compile the graph\ngraph_with_all_tools = graph_builder.compile()\n\n# Optional: visualize\n#from IPython.display import Image\n#Image(graph_with_all_tools.get_graph().draw_mermaid_png())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"state = graph_with_all_tools.invoke({\"messages\": []}, config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ✅ Capstone GenAI Capabilities Used:\n- **Structured Output**: Warm, structured responses.\n- **Few-shot Prompting**: Conversational reframing and empathetic responses.\n- **Grounded Interaction**: Simulates supportive mood check-ins using Gemini.","metadata":{}},{"cell_type":"markdown","source":" ### 🔗[Blog Post Link](http://github.com/pylkra/Google_GenAI/blob/main/gemini-mental-health-assistant.md) ###\n","metadata":{}},{"cell_type":"markdown","source":"## 🚀 Project Summary:\nI built a Gemini-powered Mental Health Assistant 🤖 to provide supportive and CBT-informed conversations for users struggling with anxiety, stress, or low mood 🧠💬.\n\nUsing LangChain + RAG 📚 and Google’s GenAI models, the assistant can retrieve helpful information and respond with empathy and guidance.\n\n🔧 The assistant is designed to be safe, responsive, and user-friendly — laying the groundwork for AI-assisted mental health support 🌈.\n\n💡 This project helped me deepen my understanding of LLMs, prompt engineering, and mental health applications in AI — and I'm proud to share it as my Google GenAI Capstone! 🎓✨","metadata":{}}]}